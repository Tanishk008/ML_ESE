{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9cf61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# IMPORTS\n",
    "# ==========================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# ==========================================================\n",
    "# CONFIG\n",
    "# ==========================================================\n",
    "TARGET_COL = \"quality_grade\"\n",
    "ID_COL = \"id\"\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# ==========================================================\n",
    "# LOAD DATA\n",
    "# ==========================================================\n",
    "train = pd.read_csv(\"/kaggle/input/mle-ese-mock/train (5).csv\")\n",
    "test  = pd.read_csv(\"/kaggle/input/mle-ese-mock/test (4).csv\")\n",
    "sample_submission = pd.read_csv(\"/kaggle/input/mle-ese-mock/submission (6).csv\")\n",
    "\n",
    "# ==========================================================\n",
    "# TARGET SAFETY (CRITICAL)\n",
    "# ==========================================================\n",
    "train = train.dropna(subset=[TARGET_COL]).reset_index(drop=True)\n",
    "\n",
    "# ==========================================================\n",
    "# SPLIT FEATURES & TARGET\n",
    "# ==========================================================\n",
    "X = train.drop(\n",
    "    columns=[TARGET_COL] + ([ID_COL] if ID_COL in train.columns else []),\n",
    "    errors=\"ignore\"\n",
    ")\n",
    "y = train[TARGET_COL]\n",
    "\n",
    "X_test = test.drop(\n",
    "    columns=[ID_COL] if ID_COL in test.columns else [],\n",
    "    errors=\"ignore\"\n",
    ")\n",
    "\n",
    "# ==========================================================\n",
    "# COLUMN TYPES\n",
    "# ==========================================================\n",
    "num_cols = X.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "cat_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "\n",
    "# ==========================================================\n",
    "# PREPROCESSING (LEAKAGE-SAFE)\n",
    "# ==========================================================\n",
    "numeric_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(\n",
    "        handle_unknown=\"ignore\",\n",
    "        min_frequency=5,          # prevents rare-category overfit\n",
    "        sparse_output=False\n",
    "    ))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_pipeline, num_cols),\n",
    "    (\"cat\", categorical_pipeline, cat_cols)\n",
    "])\n",
    "\n",
    "# ==========================================================\n",
    "# BASE MODELS (BIASâ€“VARIANCE BALANCED)\n",
    "# ==========================================================\n",
    "\n",
    "# Strong linear baseline (low variance)\n",
    "log_reg = LogisticRegression(\n",
    "    max_iter=3000,\n",
    "    multi_class=\"multinomial\",\n",
    "    solver=\"lbfgs\",\n",
    "    C=1.0,                       # regularization\n",
    "    class_weight=\"balanced\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Non-linear model (low bias)\n",
    "hgb = HistGradientBoostingClassifier(\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    max_iter=300,\n",
    "    l2_regularization=0.1,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# ==========================================================\n",
    "# CALIBRATION (IMPROVES LOG LOSS)\n",
    "# ==========================================================\n",
    "log_reg_cal = CalibratedClassifierCV(\n",
    "    estimator=log_reg,\n",
    "    method=\"isotonic\",\n",
    "    cv=3\n",
    ")\n",
    "\n",
    "# ==========================================================\n",
    "# PIPELINES\n",
    "# ==========================================================\n",
    "pipelines = {\n",
    "    \"LogisticRegression\": Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", log_reg_cal)\n",
    "    ]),\n",
    "    \"HistGradientBoosting\": Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", hgb)\n",
    "    ])\n",
    "}\n",
    "\n",
    "# ==========================================================\n",
    "# CROSS-VALIDATION (ROBUST)\n",
    "# ==========================================================\n",
    "cv = StratifiedKFold(\n",
    "    n_splits=5,\n",
    "    shuffle=True,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "scoring = {\n",
    "    \"log_loss\": \"neg_log_loss\",\n",
    "    \"accuracy\": \"accuracy\"\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, pipe in pipelines.items():\n",
    "    scores = cross_validate(\n",
    "        pipe,\n",
    "        X,\n",
    "        y,\n",
    "        cv=cv,\n",
    "        scoring=scoring,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    results.append([\n",
    "        name,\n",
    "        -scores[\"test_log_loss\"].mean(),\n",
    "        scores[\"test_accuracy\"].mean()\n",
    "    ])\n",
    "\n",
    "results_df = pd.DataFrame(\n",
    "    results,\n",
    "    columns=[\"Model\", \"CV Log Loss\", \"CV Accuracy\"]\n",
    ").sort_values(\"CV Log Loss\")\n",
    "\n",
    "print(\"\\nMODEL COMPARISON\")\n",
    "print(results_df)\n",
    "\n",
    "# ==========================================================\n",
    "# SELECT BEST MODEL\n",
    "# ==========================================================\n",
    "best_model_name = results_df.iloc[0][\"Model\"]\n",
    "best_pipeline = pipelines[best_model_name]\n",
    "\n",
    "print(f\"\\nBest Model Selected: {best_model_name}\")\n",
    "\n",
    "# ==========================================================\n",
    "# FINAL TRAINING\n",
    "# ==========================================================\n",
    "best_pipeline.fit(X, y)\n",
    "\n",
    "# ==========================================================\n",
    "# PROBABILITY PREDICTIONS\n",
    "# ==========================================================\n",
    "test_proba = best_pipeline.predict_proba(X_test)\n",
    "\n",
    "# ==========================================================\n",
    "# SUBMISSION\n",
    "# ==========================================================\n",
    "submission = pd.DataFrame(\n",
    "    test_proba,\n",
    "    columns=best_pipeline.named_steps[\"model\"].classes_\n",
    ")\n",
    "\n",
    "if \"id\" in sample_submission.columns:\n",
    "    submission.insert(0, \"id\", test[\"id\"].values)\n",
    "\n",
    "submission = submission[sample_submission.columns]\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(\"submission.csv created successfully\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
