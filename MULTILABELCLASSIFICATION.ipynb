{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199991cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# IMPORTS\n",
    "# ==========================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import make_scorer, f1_score, hamming_loss\n",
    "\n",
    "# ==========================================================\n",
    "# CONFIG\n",
    "# ==========================================================\n",
    "LABEL_COLS = [\n",
    "    \"Computer Science\",\n",
    "    \"Physics\",\n",
    "    \"Mathematics\",\n",
    "    \"Statistics\",\n",
    "    \"Quantitative Biology\",\n",
    "    \"Quantitative Finance\"\n",
    "]\n",
    "\n",
    "ID_COL = \"id\"\n",
    "RANDOM_STATE = 42\n",
    "MISSING_THRESHOLD = 0.6\n",
    "\n",
    "# ==========================================================\n",
    "# LOAD DATA\n",
    "# ==========================================================\n",
    "train = pd.read_csv('/content/train.csv')\n",
    "test  = pd.read_csv('/content/test.csv')\n",
    "\n",
    "train.drop_duplicates(inplace=True)\n",
    "\n",
    "# ==========================================================\n",
    "# DROP ROWS WITH ALL LABELS MISSING\n",
    "# ==========================================================\n",
    "train = train.dropna(subset=LABEL_COLS, how=\"all\").reset_index(drop=True)\n",
    "\n",
    "# ==========================================================\n",
    "# DROP HIGH MISSING COLUMNS\n",
    "# ==========================================================\n",
    "missing_ratio = train.isnull().mean()\n",
    "drop_cols = missing_ratio[missing_ratio > MISSING_THRESHOLD].index\n",
    "\n",
    "train.drop(columns=drop_cols, inplace=True)\n",
    "test.drop(columns=drop_cols, inplace=True, errors=\"ignore\")\n",
    "\n",
    "# ==========================\n",
    "# SPLIT FEATURES & TARGET\n",
    "# ==========================\n",
    "X = train.drop(columns=LABEL_COLS + [ID_COL], errors=\"ignore\")\n",
    "y = train[LABEL_COLS]\n",
    "\n",
    "X_test_final = test.drop(columns=[ID_COL], errors=\"ignore\")\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# COLUMN TYPES\n",
    "# ==========================================================\n",
    "num_cols = X.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "cat_cols = X.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "# ==========================================================\n",
    "# PREPROCESSING\n",
    "# ==========================================================\n",
    "numeric_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_pipeline, num_cols),\n",
    "    (\"cat\", categorical_pipeline, cat_cols)\n",
    "])\n",
    "\n",
    "# ==========================================================\n",
    "# MODELS (MULTI-LABEL WRAPPED)\n",
    "# ==========================================================\n",
    "models = {\n",
    "    \"Logistic Regression\": MultiOutputClassifier(\n",
    "        LogisticRegression(max_iter=1000)\n",
    "    ),\n",
    "    \"Random Forest\": MultiOutputClassifier(\n",
    "        RandomForestClassifier(\n",
    "            n_estimators=300,\n",
    "            random_state=RANDOM_STATE\n",
    "        )\n",
    "    )\n",
    "}\n",
    "\n",
    "# ==========================================================\n",
    "# CROSS-VALIDATION (NO STRATIFICATION)\n",
    "# ==========================================================\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "scoring = {\n",
    "    \"micro_f1\": make_scorer(f1_score, average=\"micro\"),\n",
    "    \"hamming\": make_scorer(hamming_loss, greater_is_better=False)\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "\n",
    "    scores = cross_validate(\n",
    "        pipe,\n",
    "        X,\n",
    "        y,\n",
    "        cv=cv,\n",
    "        scoring=scoring,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    results.append([\n",
    "        name,\n",
    "        scores[\"test_micro_f1\"].mean(),\n",
    "        -scores[\"test_hamming\"].mean()\n",
    "    ])\n",
    "\n",
    "# ==========================================================\n",
    "# RESULTS\n",
    "# ==========================================================\n",
    "results_df = pd.DataFrame(\n",
    "    results,\n",
    "    columns=[\"Model\", \"CV Micro-F1\", \"CV (1 - Hamming Loss)\"]\n",
    ").sort_values(\"CV Micro-F1\", ascending=False)\n",
    "\n",
    "print(\"\\nðŸ“Š MODEL COMPARISON (MULTI-LABEL)\")\n",
    "print(results_df)\n",
    "\n",
    "# ==========================================================\n",
    "# BEST MODEL\n",
    "# ==========================================================\n",
    "best_model_name = results_df.iloc[0][\"Model\"]\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "print(f\"\\nâœ… Best Model Selected: {best_model_name}\")\n",
    "\n",
    "# ==========================================================\n",
    "# FINAL TRAINING\n",
    "# ==========================================================\n",
    "final_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", best_model)\n",
    "])\n",
    "\n",
    "final_pipeline.fit(X, y)\n",
    "\n",
    "# ==========================================================\n",
    "# SUBMISSION\n",
    "# ==========================================================\n",
    "test_pred = final_pipeline.predict(X_test_final)\n",
    "\n",
    "submission = pd.DataFrame(test_pred, columns=LABEL_COLS)\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(\"submission.csv saved âœ…\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
